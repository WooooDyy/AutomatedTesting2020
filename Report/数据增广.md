# 数据增广

## 代码框架与思路

- 本次作业的数据增广代码采用python编写，基于**imgaug**的库来进行扩增。
- 选用cifar-10和cifar-100数据集，这两种数据集比较类似，所以我们使用的数据增广方法大多类似，只会在细节上有所区别。
- 代码大体思路如下：
  1. 我们首先写一个包装类来包装一个数据集对应的扩增类，比如类`imgaug_class_cifar10`，类的`init`函数接受数据集以及batch_size作为参数。
  2. 接着我们在类中使用**函数**的形式实现我们需要使用的所有增广策略，这些策略基于imgaug的接口实现。函数的返回值是增广后的数据集。
  3. 然后我们就可以创建类的实例，调用函数进行数据增广。
  4. 最后我们将增广后的数据（x和y，图像和标签）分别存储成`.npy`文件，其中图像文件文件名格式为`aug_imgs_序号_增广策略_x.npy`，比如crop变换之后的图像文件为`aug_imgs_1_crop_x.npy`，标签文件文件名格式为`aug_imgs_序号_增广策略_y.npy`，比如crop变换后标签文件为`aug_imgs_i_crop_y.npy`。这些文件可以用来做后续数据评估。
- 目前已经可以查到有许多种数据增广策略，比如裁剪、平移、旋转等，本次作业中不仅仅输出单独使用一种增广策略得到的增广数据集，还输出使用多种增广策略的数据集。
- 本次作业不会包含太多数据量的增广。对于每个数据集的每种方法，不会提交所有数据的增广结果，只会生成大小为10000的数据集。

## 单独使用一种增广策略

### 裁剪Cropping

- 裁剪技术意思是，裁剪出每个图像的中央色块，去掉一些没有必要的色块。裁剪图像可以用作高度和宽度尺寸混合的图像数据的实际处理步骤。 另外，随机裁切还可以用于提供与平移非常相似的效果。 随机裁剪和平移之间的对比在于，裁剪会减小输入的大小，例如（256,256）→（224，224），而平移会保留图像的空间尺寸。裁剪时要注意裁剪的比例，因为过大的裁剪可能使得转换后的图片难以保留标签。
- 本次作业中，采用的裁剪范围是（0，0.25），以保证数据增广后保留原来的标签。

### 平移Shifting

- 向左，向右，向上或向下移动图像对于避免数据中的**位置偏差**可能是非常有用的转换，这种转换有利于之后模型训练的准确性和鲁棒性。 例如，如果数据集中的所有图像都居中（这在人脸识别数据集中很常见），那么这也需要在完美居中（perfectly centered）的图像上测试模型，否则难以得到准确地结论。 当原始图像沿某个方向平移时，剩余空间可以用恒定值（例如0 s或255 s）填充，也可以用随机或高斯噪声填充。 该填充保留了增影后图像的空间尺寸。
- 本次作业中，在x方向和y方向采用的平移范围是（-0.20，0.20）。这使得图像主要内容不会被移出。

### 旋转Rotating

- 旋转图像增强是通过指定旋转角度后左右旋转图像来完成的。 旋转增强的可行性在很大程度上取决于旋转度的参数。 轻微旋转可能对数字识别任务（例如MNIST）有用，但是随着旋转度的增加，转换后的数据标签将不再保留。而对于类似cifar-10、cifar-100的数据集图像来说，旋转角度增加一些是可行的。
- 本次作业中，采用旋转角度是（-30，30）。

### 翻转Flipping

- 翻转包括水平方向的翻转和垂直方向的翻转。在实际操作中，水平翻转比垂直翻转更加普遍。这种方法已被证明对cifar-10等数据集很有用，但是当涉及到文字（如MNIST）时，它会导致错误，标签无法保留。
- 本次作业中，选择了cifar-10和cifar-100，认为翻转都是可行的。水平翻转和垂直翻转我们都设置0.5的概率，即有0.5的概率可能被水平翻转或垂直翻转。

### 色彩空间Color Space

- 图像数据被编码为3个堆叠的矩阵，每个矩阵的大小为（高×宽）。这些矩阵代表单个RGB颜色值的像素值。我们可以通过简单的矩阵运算轻松地控制RGB值，以增加或减少图像的亮度（brightness）；也可以使用类似的手段来改变图像的对比度（contrast）。但是色彩变换必须在一定范围内才能保证图片标签能够被保留，所以在使用时要注意参数设置。
- 本次作业中，采用的亮度乘数范围是（0.8，1.2）；采用的对比度乘数范围是（0.75，1.25）。

### 噪点插入Noise Injection

- 噪点插入是指在图像中或多或少得插入一些无关的色点，让图像变得与原来不完全一样。这种方式可以使得模型训练得更强、鲁棒性更高。但是插入噪点必须在合理范围内，如果插入噪点过多，会导致图像失真的情况出现。
- 本次作业中，采用添加高斯噪音的方式来插入噪点。噪点插入中，产生噪声的正态分布的标准偏差参数取(0.0, 0.2 * 255)。

## 多种数据增广策略组合使用

- 仅仅使用一种数据增广策略获得的数据会显得比较单薄，并且获得的数据量可能仍然不够。所以我们可以采用多种增广策略组合的方式来弥补，这些增广的数据也可以使得后续训练后的模型鲁棒性更好。上述提到的所有单个增广策略都可以进行自由组合，但是必须得要注意“标签保留”的问题。本次作业以“裁剪+旋转变换+明亮度变换”、“平移变换+噪点插入”为例，进行数据增广。

### 裁剪+旋转+明亮度

- 由于采用了三种数据增广的技术，数据失真、标签丢失的可能性大大增加，因此在参数设置时，我们选择更为保守的方法来进行增广。作业中，裁剪范围缩小为（0，0.05）；旋转范围收缩为（-10，10）；明亮度乘数收缩为（0.9，1.1）。

### 平移+噪点插入

- 同样，我们在设置参数时采用更为保守的策略来保证数据的可用性。x方向和y方向的平移范围收缩为（-0.05,0.05）；产生噪声的正态分布的标准偏差参数取(0.0, 0.05 * 255)



## Reference

[1] Shorten C, Khoshgoftaar T M. A survey on image data augmentation for deep learning[J]. Journal of Big Data, 2019, 6(1): 60.

[2] Perez L, Wang J. The effectiveness of data augmentation in image classification using deep learning[J]. arXiv preprint arXiv:1712.04621, 2017.

[3] Wang J, Perez L. The effectiveness of data augmentation in image classification using deep learning[J]. Convolutional Neural Networks Vis. Recognit, 2017, 11.

[4] https://github.com/aleju/imgaug

[5] https://imgaug.readthedocs.io/en/latest/source/installation.html





# 数据评估

## 代码框架与思路

1. 首先，做一些准备工作，编写一个数据评估类eval_class，该类详情如下：

> 属性：
>        1. 数据集（cifar10或cifar100）
>     2. 数据类别classes_list（10或100）
>     3. 批量大小batch_size
>     4. 增强数据集 x_true，y_true
>     5. 增广策略（比如crop、shift等）
>     6. 模型
>
> 函数：
>
> 1. init（）：初始化数据集、数据类别list、批量大小、增强数据集
> 2. accuracy（）：准确率，用来评估某个模型在某种增广策略下的表现
> 3. predictiong（）：预测函数，用来预测某一张图片的分类，之后会调用accuracy（）来进行评估准确率

2. 然后，测试模型对原始数据集分类的表现，类似于baseline。因为两个数据集都有60000张图片，数据量过大，所以我们选取20000张来进行测试。只需创建一个上述数据评估类的实例，然后输入相应的参数进行初始化，调用相应函数测试每个模型对未增强数据集分类的表现，结果如下表：

   - |                        | Cifar-10 | Cifar-100 |
     | ---------------------- | -------- | --------- |
     | CNN_with_dropout       | 0.65     | 0.44      |
     | CNN_without_dropout    | 0.72     | 0.82      |
     | ResNet_v1              | 0.69     | 0.29      |
     | ResNet_v2              | 0.72     | 0.31      |
     | lenet5_with_dropout    | 0.67     | 0.55      |
     | lenet5_without_dropout | 0.75     | 0.90      |
     | random1                | 0.11     | 0.009     |
     | random2                | 0.11     | 0.011     |

3. 之后就可以对增广后的图片进行评估，测试每个模型对增广后图片进行分类的准确率。同样是创建实例，读取相应方法、数据集对应的npy文件，比如读取使用crop方法扩增后的cifar10数据集`aug_imgs_cifar10_crop_x.npy`、`aug_imgs_cifar10_crop_y.npy`,然后初始化实例、调用函数计算。

4. 最后，对得到的数据进行分析与评估。使用相应度量方法（对于模型鲁棒性的提升效果）对数据质量进行评估。













- 对原始数据的预测准确率表现如下表：

|                        | Cifar-10 | Cifar-100 |
| ---------------------- | -------- | --------- |
| CNN_with_dropout       | 0.65     | 0.44      |
| CNN_without_dropout    | 0.72     | 0.82      |
| ResNet_v1              | 0.69     | 0.29      |
| ResNet_v2              | 0.72     | 0.31      |
| lenet5_with_dropout    | 0.67     | 0.55      |
| lenet5_without_dropout | 0.75     | 0.90      |
| random1                | 0.11     | 0.009     |
| random2                | 0.11     | 0.011     |

## Cifar-10



|                                 | base | Crop | Shift | Rotate | Fliplr | Flipud | Gaussian Noise | Brightness | Contrast | Brop<br>Rotate& <br>Brightness | Shift&<br>Noise |
| ------------------------------- | ---- | ---- | ----- | ------ | ------ | ------ | -------------- | ---------- | -------- | ------------------------------ | --------------- |
| CNN\_<br>with_<br>dropout       | 0.65 | 0.58 | 0.48  | 0.59   | 0.64   | 0.50   | 0.38           | 0.64       | 0.64     | 0.64                           | 0.59            |
| CNN\_<br>without_<br>dropout    | 0.72 | 0.58 | 0.51  | 0.62   | 0.72   | 0.53   | 0.43           | 0.72       | 0.72     | 0.68                           | 0.68            |
| ResNet_v1                       | 0.69 | 0.45 | 0.45  | 0.46   | 0.69   | 0.49   | 0.30           | 0.69       | 0.69     | 0.50                           | 0.46            |
| ResNet_v2                       | 0.72 | 0.52 | 0.54  | 0.53   | 0.72   | 0.53   | 0.26           | 0.72       | 0.72     | 0.60                           | 0.44            |
| lenet5\_<br>with_<br>dropout    | 0.67 |      |       |        |        |        |                |            |          |                                |                 |
| lenet5\_<br>without_<br>dropout | 0.75 |      |       |        |        |        |                |            |          |                                |                 |
| random1                         | 0.11 |      |       |        |        |        |                |            |          |                                |                 |
| random2                         | 0.11 |      |       |        |        |        |                |            |          |                                |                 |



- 丢失率公式:
- ba: base_accuracy，模型对未增广图片的预测正确率
- aa: augmentated accuracy，模型对增广后图片的预测正确率

$$
loss\_rate = (ba-aa)/ba
$$



对比base的差值：



|                                 | base | Crop  | Shift | Rotate | Fliplr | Flipud | Gaussian Noise | Brightness | Contrast | Brop<br>Rotate& <br>Brightness | Shift&<br>Noise |
| ------------------------------- | ---- | ----- | ----- | ------ | ------ | ------ | -------------- | ---------- | -------- | ------------------------------ | --------------- |
| CNN\_<br>with_<br>dropout       | 0.65 | -0.07 | -0.17 | -0.06  | -0.01  | -0.15  | -0.27          | -0.01      | -0.01    | -0.01                          | -0.06           |
| CNN\_<br>without_<br>dropout    | 0.72 | -0.14 | -0.21 | -0.10  | 0.00   | -0.19  | -0.29          | 0.00       | 0.00     | -0.04                          | -0.04           |
| ResNet_v1                       | 0.69 | -0.24 | -0.24 | -0.23  | 0.00   | -0.20  | -0.39          | 0.00       | 0.00     | -0.19                          | -0.23           |
| ResNet_v2                       | 0.72 | -0.20 | -0.18 | -0.19  | 0.00   | -0.19  | -0.46          | 0.00       | 0.00     | -0.12                          | -0.28           |
| lenet5\_<br>with_<br>dropout    | 0.67 |       |       |        |        |        |                |            |          |                                |                 |
| lenet5\_<br>without_<br>dropout | 0.75 |       |       |        |        |        |                |            |          |                                |                 |
| random1                         | 0.11 |       |       |        |        |        |                |            |          |                                |                 |
| random2                         | 0.11 |       |       |        |        |        |                |            |          |                                |                 |

- 我们做数据评估的质量指标是数据对于模型鲁棒性提升的能力。因此模型对某个扩增数据集的预测越不准确，我们就认为这个数据集质量较高。
- 通过比较我们发现，通过对cifar-10采取颜色空间（color space）变换（比如对比度、亮度）生成的数据集，质量并不高。因为使用这些数据测出来的模型预测准确率与使用未增强数据测试出来的区别并不大，所以它们对于模型鲁棒性的提升并不高。
- 而通过对cifar-10采取几何变换生成的扩增数据集，对于模型鲁棒性的提升很大。比如裁剪、平移、旋转等等，它们使得模型的预测准确率下降了不少，可以说模型对于这些变换的适应性不太好，有待增强。
- 有意思的一点是，在几何变换中，通过水平翻转fliplr和垂直翻转flipud扩增产生的数据集展现了完全不同的质量。模型对通过水平翻转的数据集分类预测非常准确，接近100%，所以对模型鲁棒性的提升不大，也表明模型在这方面鲁棒性比较高。而对垂直翻转的数据集分类预测不是很准确，因此我们认为其质量较高，对模型鲁棒性的提升很大。





## Cifar-100